{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a03723e-78ae-4150-ba22-e2e485b95cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Planetary Computer Tools for accessing and working with Planetary Computer data\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "import planetary_computer as pc\n",
    "from odc.stac import stac_load\n",
    "pc.settings.set_subscription_key('e9c294b01b2f483082124b8329af819f') # INSERT YOUR KEY HERE\n",
    "\n",
    "# Requests for making HTTP requests\n",
    "import requests\n",
    "\n",
    "# Rich for creating rich-text tables\n",
    "from rich.table import Table\n",
    "\n",
    "# Itertools for creating an iterator cycling through a sequence indefinitely\n",
    "from itertools import cycle\n",
    "\n",
    "# TQDM for creating progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data Science\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c268cf6",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80dbf04",
   "metadata": {},
   "source": [
    "Before building the model, we need to load in the rice crop presence data. We have curated for you data from a certain region in Vietnam for the year 2020. The data consists of  geo locations (Latitude and Longitude) with a tag specifying if the crop present in each geo location is rice or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1da678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice\n",
       "1  (10.322364360592521, 105.27843410554115)          Rice\n",
       "2  (10.321455902933202, 105.25254306225168)          Rice\n",
       "3  (10.324181275911162, 105.25118037576274)          Rice\n",
       "4  (10.324635504740822, 105.27389181724476)          Rice"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_presence_data = pd.read_csv(\"Crop_Location_Data_20221201.csv\")\n",
    "#crop_presence_data = pd.read_csv(\"TEST_Crop_Location.csv\")\n",
    "\n",
    "crop_presence_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6812c-7137-4873-b4ed-2dcdd470209b",
   "metadata": {},
   "source": [
    "## Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1487a9dc-1308-4c05-a69a-ccfe60bc9100",
   "metadata": {},
   "source": [
    "<p align =\"justify\">Now that we have our crop location data, it is time to gather the predictor variables from the Sentinel-1 dataset. For a more in-depth look regarding the Sentinel-1 dataset and how to query it, see the Sentinel-1 <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/6403146221623637-63ca8d537b1fe300146c79d0-Sentinel%201%20Phenology.ipynb/\"> supplementary \n",
    "notebook</a>.\n",
    "    \n",
    "\n",
    "<p align = \"justify\">Sentinel-1 radar data penetrates through the clouds, thus helping us to get the band values with minimal atmospheric attenuation. Band values such as VV and VH help us in distinguishing between the rice and non rice crops. Hence we are choosing VV and VH as predictor variables for this experiment. \n",
    "        \n",
    "<ul>\n",
    "<li>VV - gamma naught values of signal transmitted with vertical polarization and received with vertical polarization with radiometric terrain correction applied.\n",
    "\n",
    "<li>VH - gamma naught values of signal transmitted with vertical polarization and received with horizontal polarization with radiometric terrain correction applied.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85257f-4a48-49e8-8036-10e9a6b69894",
   "metadata": {},
   "source": [
    "### Accessing the Sentinel-1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399737c-46bb-44b7-bda8-4253c827e66d",
   "metadata": {},
   "source": [
    "<p align = \"Justify\">To get the Sentinel-1 data, we write a function called <i><b>get_sentinel_data.</b></i> This function will fetch VV and VH band values for a particular location over the specified time window. In this example, we have extracted VV and VH values for a day (21st March 2020). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb9b25-0c41-4f55-aa33-082adeb34dbd",
   "metadata": {},
   "source": [
    "Explore the approach of building a bounding box (e.g., 5x5 pixels) around the given latitude and longitude positions and then extract the aggregated band values (e.g., average, median) to get normalized band values to build the model. Radar data has inherent variability at the pixel level due to variable scattering response from the target. This effect is called “speckle” and it is common to filter the data to smooth these variations. Try using a 3x3, 5x5 or 7x7 window around the specific latitude and longitude point to get improved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e339a34-cfa7-4899-9165-63ca7c01bbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_sentinel_data(latlong, time_slice):\\n    \\n    #Returns VV and VH values for a given latitude and longitude \\n    #Attributes:\\n    #latlong - A tuple with 2 elements - latitude and longitude\\n    #time_slice - Timeframe for which the VV and VH values have to be extracted\\n    \\n\\n    latlong = latlong.replace(\\'(\\', \\'\\').replace(\\')\\', \\'\\').replace(\\' \\', \\'\\').split(\\',\\')\\n    lat, lon = map(float, latlong)\\n    \\n    box_size_deg = 0.0004  # Surrounding box in degrees, yields approximately 5x5 pixel region\\n    min_lon = lon - box_size_deg/2\\n    min_lat = lat - box_size_deg/2\\n    max_lon = lon + box_size_deg/2\\n    max_lat = lat + box_size_deg/2\\n    \\n    bbox_of_interest = (min_lon, min_lat, max_lon, max_lat)\\n    time_of_interest = time_slice\\n\\n    catalog = pystac_client.Client.open(\\n        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\\n    )\\n    search = catalog.search(\\n        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\\n    )\\n    items = list(search.get_all_items())\\n    \\n    # Define the pixel resolution for the final product\\n    # Define the scale according to our selected crs, so we will use degrees\\n    resolution = 10  # meters per pixel \\n    scale = resolution / 111320.0  # degrees per pixel for crs=4326 \\n    \\n    # Load the data using Open Data Cube\\n    data = stac_load(items, bands=[\"vv\", \"vh\"], patch_url=pc.sign, bbox=bbox_of_interest, crs=\"EPSG:4326\", resolution=scale)\\n    \\n    # Calculate the mean of the data across the sample region\\n    mean = data.mean(dim=[\\'latitude\\', \\'longitude\\']).compute()\\n    \\n    # Calculate RVI\\n    dop = (mean.vv / (mean.vv + mean.vh))\\n    m = 1 - dop\\n    rvi = (np.sqrt(dop)) * ((4 * mean.vh) / (mean.vv + mean.vh))\\n\\n    # Calculate the averaged values\\n    vh_avg = mean.vh.mean().values.item()\\n    vv_avg = mean.vv.mean().values.item()\\n    rvi_avg = rvi.mean().values.item()\\n    \\n    return vh_avg, vv_avg, rvi_avg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_sentinel_data(latlong, time_slice):\n",
    "    \n",
    "    #Returns VV and VH values for a given latitude and longitude \n",
    "    #Attributes:\n",
    "    #latlong - A tuple with 2 elements - latitude and longitude\n",
    "    #time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    \n",
    "\n",
    "    latlong = latlong.replace('(', '').replace(')', '').replace(' ', '').split(',')\n",
    "    lat, lon = map(float, latlong)\n",
    "    \n",
    "    box_size_deg = 0.0004  # Surrounding box in degrees, yields approximately 5x5 pixel region\n",
    "    min_lon = lon - box_size_deg/2\n",
    "    min_lat = lat - box_size_deg/2\n",
    "    max_lon = lon + box_size_deg/2\n",
    "    max_lat = lat + box_size_deg/2\n",
    "    \n",
    "    bbox_of_interest = (min_lon, min_lat, max_lon, max_lat)\n",
    "    time_of_interest = time_slice\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\n",
    "    )\n",
    "    items = list(search.get_all_items())\n",
    "    \n",
    "    # Define the pixel resolution for the final product\n",
    "    # Define the scale according to our selected crs, so we will use degrees\n",
    "    resolution = 10  # meters per pixel \n",
    "    scale = resolution / 111320.0  # degrees per pixel for crs=4326 \n",
    "    \n",
    "    # Load the data using Open Data Cube\n",
    "    data = stac_load(items, bands=[\"vv\", \"vh\"], patch_url=pc.sign, bbox=bbox_of_interest, crs=\"EPSG:4326\", resolution=scale)\n",
    "    \n",
    "    # Calculate the mean of the data across the sample region\n",
    "    mean = data.mean(dim=['latitude', 'longitude']).compute()\n",
    "    \n",
    "    # Calculate RVI\n",
    "    dop = (mean.vv / (mean.vv + mean.vh))\n",
    "    m = 1 - dop\n",
    "    rvi = (np.sqrt(dop)) * ((4 * mean.vh) / (mean.vv + mean.vh))\n",
    "\n",
    "    # Calculate the averaged values\n",
    "    vh_avg = mean.vh.mean().values.item()\n",
    "    vv_avg = mean.vv.mean().values.item()\n",
    "    rvi_avg = rvi.mean().values.item()\n",
    "    \n",
    "    return vh_avg, vv_avg, rvi_avg'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28653a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel_data(latlong, time_slice):\n",
    "    '''\n",
    "    Returns VV and VH values for a given latitude and longitude \n",
    "    Attributes:\n",
    "    latlong - A tuple with 2 elements - latitude and longitude\n",
    "    time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    '''\n",
    "\n",
    "    latlong = latlong.replace('(', '').replace(')', '').replace(' ', '').split(',')\n",
    "    lat, lon = map(float, latlong)\n",
    "    \n",
    "    #box_size_deg = 0.0004  # Surrounding box in degrees, yields approximately 5x5 pixel region\n",
    "    box_size_deg = 0.0125\n",
    "    \n",
    "    min_lon = lon - box_size_deg/2\n",
    "    min_lat = lat - box_size_deg/2\n",
    "    max_lon = lon + box_size_deg/2\n",
    "    max_lat = lat + box_size_deg/2\n",
    "    \n",
    "    bbox_of_interest = (min_lon, min_lat, max_lon, max_lat)\n",
    "    time_of_interest = time_slice\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "    search = catalog.search(\n",
    "        collections=[\"sentinel-1-rtc\"], bbox=bbox_of_interest, datetime=time_of_interest\n",
    "    )\n",
    "    items = list(search.get_all_items())\n",
    "    \n",
    "    # Define the pixel resolution for the final product\n",
    "    # Define the scale according to our selected crs, so we will use degrees\n",
    "    resolution = 10  # meters per pixel \n",
    "    scale = resolution / 111320.0  # degrees per pixel for crs=4326 \n",
    "    \n",
    "    # Load the data using Open Data Cube\n",
    "    data = stac_load(items, bands=[\"vv\", \"vh\"], patch_url=pc.sign, bbox=bbox_of_interest, crs=\"EPSG:4326\", resolution=scale)\n",
    "    \n",
    "    # Calculate the statistics of VH and VV\n",
    "    vh_min = data.vh.min().values.item()\n",
    "    vh_max = data.vh.max().values.item()\n",
    "    vh_median = np.median(data.vh).item()\n",
    "\n",
    "    vv_min = data.vv.min().values.item()\n",
    "    vv_max = data.vv.max().values.item()\n",
    "    vv_median = np.median(data.vv).item()\n",
    "\n",
    "    # Calculate the mean of the data across the sample region\n",
    "    mean = data.mean(dim=['latitude', 'longitude']).compute()\n",
    "    \n",
    "    # Calculate RVI\n",
    "    dop = (mean.vv / (mean.vv + mean.vh))\n",
    "    m = 1 - dop\n",
    "    rvi = (np.sqrt(dop)) * ((4 * mean.vh) / (mean.vv + mean.vh))\n",
    "\n",
    "    # Calculate additional RVI statistics\n",
    "    rvi_min = rvi.min().values.item()\n",
    "    rvi_max = rvi.max().values.item()\n",
    "    rvi_median = np.median(rvi).item()\n",
    "    \n",
    "    # Calculate the averaged values\n",
    "    vh_avg = mean.vh.mean().values.item()\n",
    "    vv_avg = mean.vv.mean().values.item()\n",
    "    rvi_avg = rvi.mean().values.item()\n",
    "    \n",
    "    return vh_avg, vv_avg, rvi_avg, rvi_min, rvi_max, rvi_median, vh_min, vh_max, vh_median, vv_min, vv_max, vv_median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c51cd6e-41e2-4df4-ae07-349be861f0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [28:49<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "## Function call to extract VV,VH Values\n",
    "time_slice = \"2020-03-20/2020-03-21\"\n",
    "assests = ['vh','vv','rvi']\n",
    "vh_vv_rvi = []\n",
    "for coordinates in tqdm(crop_presence_data['Latitude and Longitude']):\n",
    "    vh_vv_rvi.append(get_sentinel_data(coordinates,time_slice))\n",
    "vh_vv_data = pd.DataFrame(vh_vv_rvi, columns=['vh', 'vv', 'RVI', 'RVI(min)', 'RVI(max)', 'RVI(median)', 'vh(min)', 'vh(max)', 'vh(median)', 'vv(min)', 'vv(max)', 'vv(median)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa872546-7567-418c-af04-1d8b4fa5bd60",
   "metadata": {},
   "source": [
    "## Joining the predictor variables and response variables\n",
    "Now that we have extracted our predictor variables, we need to join them onto the response variable . We use the function <i><b>combine_two_datasets</b></i> to combine the predictor variables and response variables.The <i><b>concat</b></i> function from pandas comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96296d95-8290-4f26-80f9-9e221bfcfc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_two_datasets(dataset1,dataset2):\n",
    "    '''\n",
    "    Returns a  vertically concatenated dataset.\n",
    "    Attributes:\n",
    "    dataset1 - Dataset 1 to be combined \n",
    "    dataset2 - Dataset 2 to be combined\n",
    "    '''\n",
    "    data = pd.concat([dataset1,dataset2], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fa2b5f-727b-4781-9ff4-cc70596cd3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude and Longitude</th>\n",
       "      <th>Class of Land</th>\n",
       "      <th>vh</th>\n",
       "      <th>vv</th>\n",
       "      <th>RVI</th>\n",
       "      <th>RVI(min)</th>\n",
       "      <th>RVI(max)</th>\n",
       "      <th>RVI(median)</th>\n",
       "      <th>vh(min)</th>\n",
       "      <th>vh(max)</th>\n",
       "      <th>vh(median)</th>\n",
       "      <th>vv(min)</th>\n",
       "      <th>vv(max)</th>\n",
       "      <th>vv(median)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10.323727047081501, 105.2516346045924)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.205613</td>\n",
       "      <td>0.640923</td>\n",
       "      <td>0.587695</td>\n",
       "      <td>0.694151</td>\n",
       "      <td>0.640923</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>3.314999</td>\n",
       "      <td>0.038026</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>162.339966</td>\n",
       "      <td>0.148608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10.322364360592521, 105.27843410554115)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.168547</td>\n",
       "      <td>0.701644</td>\n",
       "      <td>0.665469</td>\n",
       "      <td>0.737819</td>\n",
       "      <td>0.701644</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>1.885325</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>5.564671</td>\n",
       "      <td>0.143516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(10.321455902933202, 105.25254306225168)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.041375</td>\n",
       "      <td>0.203101</td>\n",
       "      <td>0.619992</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>0.662027</td>\n",
       "      <td>0.619992</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>3.314999</td>\n",
       "      <td>0.035738</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>162.339966</td>\n",
       "      <td>0.145177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(10.324181275911162, 105.25118037576274)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.044391</td>\n",
       "      <td>0.206562</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>0.593127</td>\n",
       "      <td>0.698088</td>\n",
       "      <td>0.645607</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>3.314999</td>\n",
       "      <td>0.038637</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>162.339966</td>\n",
       "      <td>0.149594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10.324635504740822, 105.27389181724476)</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.174365</td>\n",
       "      <td>0.704493</td>\n",
       "      <td>0.655041</td>\n",
       "      <td>0.753944</td>\n",
       "      <td>0.704493</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.467440</td>\n",
       "      <td>0.036355</td>\n",
       "      <td>0.012190</td>\n",
       "      <td>14.588789</td>\n",
       "      <td>0.147110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Latitude and Longitude Class of Land        vh        vv  \\\n",
       "0   (10.323727047081501, 105.2516346045924)          Rice  0.043734  0.205613   \n",
       "1  (10.322364360592521, 105.27843410554115)          Rice  0.040909  0.168547   \n",
       "2  (10.321455902933202, 105.25254306225168)          Rice  0.041375  0.203101   \n",
       "3  (10.324181275911162, 105.25118037576274)          Rice  0.044391  0.206562   \n",
       "4  (10.324635504740822, 105.27389181724476)          Rice  0.042551  0.174365   \n",
       "\n",
       "        RVI  RVI(min)  RVI(max)  RVI(median)   vh(min)   vh(max)  vh(median)  \\\n",
       "0  0.640923  0.587695  0.694151     0.640923  0.003147  3.314999    0.038026   \n",
       "1  0.701644  0.665469  0.737819     0.701644  0.002306  1.885325    0.033830   \n",
       "2  0.619992  0.577957  0.662027     0.619992  0.002989  3.314999    0.035738   \n",
       "3  0.645607  0.593127  0.698088     0.645607  0.003147  3.314999    0.038637   \n",
       "4  0.704493  0.655041  0.753944     0.704493  0.002744  0.467440    0.036355   \n",
       "\n",
       "    vv(min)     vv(max)  vv(median)  \n",
       "0  0.015913  162.339966    0.148608  \n",
       "1  0.007239    5.564671    0.143516  \n",
       "2  0.015913  162.339966    0.145177  \n",
       "3  0.016310  162.339966    0.149594  \n",
       "4  0.012190   14.588789    0.147110  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_data = combine_two_datasets(crop_presence_data,vh_vv_data)\n",
    "crop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f32393",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data.to_csv('crop_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
